# Umbra AI

> 🧠 A clean, privacy-respecting interface for open-source language models.

Umbra is a lightweight, no-tracking wrapper that lets you interact with open AI models like **Mistral**, **LLaMA**, **OpenChat**, and others — through a clean, minimal UI. Built with a focus on **autonomy**, **simplicity**, and **user freedom**.


---

## 🌟 Features

- ✅ **Supports open models** — Mistral, LLaMA, OpenChat, and others (via Ollama, LM Studio, etc.)
- 🧩 **Plug-and-play backends** — Swap between local or remote inference
- 🧼 **Minimalist frontend** — Focused UX, built for conversation not distraction
- 🛡️ **Zero tracking** — No telemetry, no user data collection, no ads
- 💬 **Experimental fine-tune support** — Goal: enable hosting & interaction with 65B+ and custom-trained models

---

### 🌌 Long-Term Vision: Our Own Models

While Umbra currently wraps existing open models, our long-term goal is to begin training and releasing our own models — purpose-built for user autonomy, creativity, and privacy. These models would be fine-tuned or trained from scratch on carefully curated datasets, with alignment and safety handled transparently — and without corporate filtering or behavioral bias baked in by default.

This is a big step, but one that aligns with our philosophy: users should not only control the interface, but also the intelligence behind it.

---

## 🚧 Project Status

Umbra is under active development. The goal is to make it easier to:

- Run your **own model** (without needing a gpu cluster)
- Chat with **large models** (70B+, fine-tuned) *without needing your own GPU cluster*
- Host AI experiences that are **fully in your control**

Right now, Umbra supports 9B-class models via Ollama and other inference servers. Larger model hosting is a longer-term objective as we expand backend support and access to stronger hardware.

---
## 🚀 Getting Started

### 🔗 Try out the hosted version
[https://umbraai.xyz](https://umbraai.xyz)

> Public instance — usage is anonymous and ephemeral.

---

## 🛠️ Tech Stack

- Frontend: React + Tailwind (minimal, responsive)
- Backend: Node.js + Express
- Model Bridge: Ollama / LM Studio / local inference endpoints

---

## 💬 Contributing

Pull requests and ideas are welcome — especially if you're passionate about:
- Privacy-first UX
- Model hosting / backend integrations
- UI polish
- Alt-model exploration (RWKV, Mixtral, etc.)

> Check the [issues](https://github.com/umbra-ai1/umbra-ai/issues) page or open a discussion.

---

## 💸 Support & Sustainability

Umbra is a bootstrapped product. Your use, feedback, and donations help us:

- Scale infrastructure to support larger models
- Invest in fine-tuning and future model training
- Stay independent, lean, and non-exploitative

BTC: bc1qy4dryep3tc09uvaekh6qkaslzxzlt2aqqgmwcs   
LTC: ltc1qn7memtpg88kepwuv3lm79k7dq2vvjkf7lv2sg7    
SOL: BjwBdsfadp2DKPMWeCgkbWyd2mFWnhber8s5JMPyZssf    
XMR: 84cLNScC865NsxXvSDg25AhYXctKvPcegJnRAKKUw4igJ3RNfk87oovNxM9v9b8Y1A4JR89tVR9YF833dDFWr3VeF78pRHu

Every bit goes toward hosting costs and open development.

Commercial tiers and partner licenses are coming in 2026.

---
## 🔗 Links

- [Live Demo](https://umbraai.xyz)

---

📍 See where Umbra is headed → [Roadmap.md](./docs/Roadmap.md)

---

> _“The power of AI shouldn’t come at the cost of privacy. Umbra is one step toward keeping it that way.”_

