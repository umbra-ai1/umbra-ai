# Umbra AI

> ğŸ§  A clean, privacy-respecting interface for open-source language models.

Umbra is a lightweight, no-tracking wrapper that lets you interact with open AI models like **Mistral**, **LLaMA**, **OpenChat**, and others â€” through a clean, minimal UI. Built with a focus on **autonomy**, **simplicity**, and **user freedom**.


---

## ğŸŒŸ Features

- âœ… **Supports open models** â€” Mistral, LLaMA, OpenChat, and others (via Ollama, LM Studio, etc.)
- ğŸ§© **Plug-and-play backends** â€” Swap between local or remote inference
- ğŸ§¼ **Minimalist frontend** â€” Focused UX, built for conversation not distraction
- ğŸ›¡ï¸ **Zero tracking** â€” No telemetry, no user data collection, no ads
- ğŸ’¬ **Experimental fine-tune support** â€” Goal: enable hosting & interaction with 65B+ and custom-trained models

---

### ğŸŒŒ Long-Term Vision: Our Own Models

While Umbra currently wraps existing open models, our long-term goal is to begin training and releasing our own models â€” purpose-built for user autonomy, creativity, and privacy. These models would be fine-tuned or trained from scratch on carefully curated datasets, with alignment and safety handled transparently â€” and without corporate filtering or behavioral bias baked in by default.

This is a big step, but one that aligns with our philosophy: users should not only control the interface, but also the intelligence behind it.

---

## ğŸš§ Project Status

Umbra is under active development. The goal is to make it easier to:

- Run your **own model** (without needing a gpu cluster)
- Chat with **large models** (70B+, fine-tuned) *without needing your own GPU cluster*
- Host AI experiences that are **fully in your control**

Right now, Umbra supports 9B-class models via Ollama and other inference servers. Larger model hosting is a longer-term objective as we expand backend support and access to stronger hardware.

---
## ğŸš€ Getting Started

### ğŸ”— Try out the hosted version
[https://umbraai.xyz](https://umbraai.xyz)

> Public instance â€” usage is anonymous and ephemeral.

---

## ğŸ› ï¸ Tech Stack

- Frontend: React + Tailwind (minimal, responsive)
- Backend: Node.js + Express
- Model Bridge: Ollama / LM Studio / local inference endpoints

---

## ğŸ’¬ Contributing

Pull requests and ideas are welcome â€” especially if you're passionate about:
- Privacy-first UX
- Model hosting / backend integrations
- UI polish
- Alt-model exploration (RWKV, Mixtral, etc.)

> Check the [issues](https://github.com/umbra-ai1/umbra-ai/issues) page or open a discussion.

---

## ğŸ’¸ Support & Sustainability

Umbra is a bootstrapped product. Your use, feedback, and donations help us:

- Scale infrastructure to support larger models
- Invest in fine-tuning and future model training
- Stay independent, lean, and non-exploitative

BTC: bc1qy4dryep3tc09uvaekh6qkaslzxzlt2aqqgmwcs   
LTC: ltc1qn7memtpg88kepwuv3lm79k7dq2vvjkf7lv2sg7    
SOL: BjwBdsfadp2DKPMWeCgkbWyd2mFWnhber8s5JMPyZssf    
XMR: 84cLNScC865NsxXvSDg25AhYXctKvPcegJnRAKKUw4igJ3RNfk87oovNxM9v9b8Y1A4JR89tVR9YF833dDFWr3VeF78pRHu

Every bit goes toward hosting costs and open development.

Commercial tiers and partner licenses are coming in 2026.

---
## ğŸ”— Links

- [Live Demo](https://umbraai.xyz)

---

ğŸ“ See where Umbra is headed â†’ [Roadmap.md](./docs/Roadmap.md)

---

> _â€œThe power of AI shouldnâ€™t come at the cost of privacy. Umbra is one step toward keeping it that way.â€_

